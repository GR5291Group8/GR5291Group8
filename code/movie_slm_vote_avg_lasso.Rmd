---
title: "movie_slm_sparsity_vote_avg"
author: 'Yan Qin (UNI: yq2232)'
date: "2018Äê10ÔÂ25ÈÕ"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

data_new is defined in moive_slm_sparsity_language.

1 Solve for the sparsity of language matrix
```{r}
data_vote_avg = read.csv("~/5291/Project/cleaned_movie_data_vote_average.csv", header = TRUE)
```
data_new is our new data which combines all minority languages to one variable "min_language". 
We run linear model again.

2. Get ready for regression model
---------summary statistics
```{r}
# fit linear regression models
lmod = lm(vote_average~., data = data_vote_avg)


```
3. check for colinearity 
```{r}
library(car)
# vif
vif(lmod)
# all less than 10, no colinearity is detected
```
4 Separate data into Testing and Training datasets
```{r}
set.seed(123)
# 75% of the data are training; 25% of the data are testing
smp_size = floor(0.75 * nrow(data_vote_avg))
train_ind = sample(seq_len(nrow(data_vote_avg)), size = smp_size)
train = data_vote_avg[train_ind, ]
test = data_vote_avg[-train_ind, ]
head(test)
```
5 Model Selection

LASSO
```{r}
data(train); require(glmnet)
x = data.matrix(train[,-1])
y = train$vote_average
lmod_lasso = cv.glmnet(x, y=y, alpha = 1) 
plot(lmod_lasso)
# lambda that can minimize MSE
lmod_lasso$lambda.min
# coefficients of lasso predictors
#coef(lmod_lasso, s=lmod_lasso$lambda.min)
lasso_model <- glmnet(x,y,alpha = 1,lambda = lmod_lasso$lambda.min)
coef(lasso_model)
```


6 Diagnositics
(1) Linearity
```{r}
par(mfrow = c(2,2))
plot(lassolm, 1)
summary(lassolm)$r.squared
```
R^2 is 0.4778524


(2) Normality
```{r}
hist(lmod_step_train$residuals)
qqnorm(resid(lmod_step_train))
qqline(resid(lmod_step_train))
shapiro.test(lmod_step_train$residuals)
```
p-value too small, fail

```{r}
lassolm = lm(vote_average ~ runtime + vote_count + year + month + Documentary + Crime + War + Foreign + Adventure + Western + Music + Mystery + Action + Comedy + Science.Fiction + Fantasy + Drama + Animation + Family + Horror + L4 + L6 + L9 + L10 + L12 + L13 + L15 + L33 + L50 + L52 + L53 + L54 + min_language, data = train)
lassolm
hist(lassolm$residuals)
#qqnorm(resid(lassolm))
#qqline(resid(lassolm))
shapiro.test(resid(lassolm))
```

p-values both <0.05, fail

Not normal, but qqplot looks ok

(3) Homoscedasticiy
```{r}
# graph
par(mfrow = c(2,2))
plot(lassolm)
library(lmtest)
# breush pagan test
bptest(lassolm) # p-value < 0.05
# NCV Test
ncvTest(lassolm) # p-value = 0.015 > 0.05
```
p_value <0.05, fail

(4) Uncorrelated error
```{r}
durbinWatsonTest(lassolm) # p = 0.528
```
errors are uncorrelated

(5) Outliers and influential points
```{r}
plot(cooks.distance(lassolm))
plot(lassolm, which = c(4))
# 2244, 2132, 182 are highly influential points
```
```{r}
# remove outlier
train_remove_out = train[-c(2244, 2132, 182),]

```
7 Transfromation
Log
```{r}
lmod_step_train_transform = lm(log(vote_average) ~ runtime + vote_count + year + month + Documentary + Crime + Foreign + Adventure + Western + Action + Comedy + Science.Fiction + Fantasy + Drama + Animation + Family + Horror + L4 + L9 + L12 + L15 + L50 + L53 + min_language, data = train_remove_out)
summary(lmod_step_train_transform)
```
Linearity
```{r}
par(mfrow = c(2,2))
plot(lasso_transform, 1)
summary(lasso_transform)$r.squared
```
R^2 is 0.4353424

Normality

```{r}
lasso_transform = lm(log(vote_average) ~ runtime + vote_count + year + month + Documentary + Crime + War + Foreign + Adventure + Western + Music + Mystery + Action + Comedy + Science.Fiction + Fantasy + Drama + Animation + Family + Horror + L4 + L6 + L9 + L10 + L12 + L13 + L15 + L33 + L50 + L52 + L53 + L54 + min_language, data = train)
lasso_transform
hist(lasso_transform$residuals)
qqnorm(resid(lasso_transform))
qqline(resid(lasso_transform))
shapiro.test(resid(lasso_transform))
```
p_value too small, fail

Homoscedasticity
```{r}
# graph
par(mfrow = c(2,2))
plot(lasso_transform)
# breush pagan test
bptest(lasso_transform) # p-value < 0.05
# NCV Test
ncvTest(lasso_transform) # p-value< 0.05
```
P-value <0.05,
homoscedasticity fails

Uncorrelated Errors
```{r}
durbinWatsonTest(lasso_transform) # uncorrelated
```
We should not use log transformation
keep the original model
We should use lassolm as our linear model (only normality fails)

8. Test Error
```{r}
testdata <- data.matrix(test[,-1])
lm_pred <- predict(lasso_model,newx = testdata)
error <- mean(abs((test[,1]-lm_pred)/test[,1]), na.rm = TRUE)
head(lm_pred)
error
```





####
binary variables too many, not continous, not local-best solution